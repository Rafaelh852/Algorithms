{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "This is a collection of sampling algorithms implemented in python.\n",
    "\n",
    "Some notation has been adopted to make things simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a list of distributions we will attempt to sample from\n",
    "\n",
    "|Distributions| $$ f(x) $$|\n",
    "|--- | ---- |\n",
    "Beta | \n",
    "Binomial |\n",
    "Chi square |  \n",
    "exponential | \n",
    "gamma norma univariate | \n",
    "normal multivariate | \n",
    "poisson | \n",
    "continuous uniform | |\n",
    "weibull | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of sampling is to generate data to achieve a statistically significant result from an estimate \n",
    "\n",
    "Law of large numbers\n",
    "The Law of large numbers says that your sample mean will converge to the population mean as you take more samples or larger samples\n",
    "\n",
    "we have another theroem that says we can use a uniform distribution with the proper transformation will take shape of the distribution we are looking for\n",
    "\n",
    "Markov monte carlo(simulation)\n",
    "    the monte carlo simulation takes advantage of these two theorems by saying using a random sample generated from a uniform distribution and plugged into the formula or method of interest we can simulate the average behavior of whatever the model is governing. this is used when we know the model but we dont know what will happen in practice. this gives us an idea of what will happen on average\n",
    "\n",
    "noise\n",
    "    during our simulations we do not often consider noise as we are simulating what we believe is true random. but in practice noise will occur from bad measurements faulty systems or just the nature of the problem. our most comprehensive noise pattern is a normally distributed noise. with mean of measure 0 and 1 variance that is the standard normal distribution. this is ideal because we know how this will behave and the central limit theorem suggest that all distributions will eventually reach normality under the right conditions. so if we have a normal set of noise then we know this is the end of the road for this distribution of errors we will have no more changes unless acted upon from a really strange source or particular system in wich case we know somehting is wrong. which is really usefull.\n",
    "\n",
    "when noise is not normal we have to relly on General Linear models that try to generalize noise to a special case of a parametric model or a particular type of family of distributions often it is the exponential family. \n",
    "\n",
    "Bootstrapping\n",
    "    bootstrapping is a way to sample over and over again data you already have and generate new estimates the average of these estimates is your new estimator for the parameter of interest it can be used almost instincively when you do not have the model to simulate from \n",
    "\n",
    "Cross validation\n",
    "    cross validation helps you preacess what your models will do in the future. how they will preform out in the wild by randomizing a percentage split int he data and creating two sets one where you build(train) a model with and the other where you validate or check your model performance with this is like resampling from your sample when you do not know if your sample is any good. this is like sampling squared plus a slice. like uncompleting the square if that makes sense at all\n",
    "\n",
    "simulation from posit model\n",
    "    simulation from a posit model states that after you have built a model how do you know if you have a good model? well you assume the parameters from the model you have created to be true and they are your new \"true\" parametters then if you sample form the model and you create data and use this data to create new models then if on average your new models predict the \"true\" parameters then your original model is a model that will statistically capture (on average) the population parameters\n",
    "\n",
    "stratification and random sampling\n",
    "    there aremany traditional methods of generating a \"good\" sample from your data some can be done conventionally so that you do not have to relly on bootstrapping or markov modeling to get a good estimator\n",
    "\n",
    "chips sampling for live\n",
    "    in chips book we find out that when traditional sampling is not good enough we need to relly on just intime sampling which assumes the consumption of information as a sequence and we generate a random sequence to use for modeling(training) and and one for validation like a split in the stream of data\n",
    "\n",
    "conditional sampling? like binning or buckets\n",
    "    someitmes you can sample using prior information or make models based ont his? idk this realy i need more research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the data with LDA etc\n",
    "you can split what you have sampled and then train based off categories but then you get simposons paradox and i have no idea if this is a good thing or not nobody seems to give me a clear answer. maybe i should ask someone on linked in or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
